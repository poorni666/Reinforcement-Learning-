# -*- coding: utf-8 -*-
"""evaluate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gMbV0WjGtD4YXzM9G9TA1vpLSjaiqxOp
"""



import random
import torch
from collections import Counter
from wordle_agent import masked_softmax


def evaluate_agent_with_games(episode_num, num_display_games=2):
    """ demo games"""
    wins, total_guesses = 0, 0

    print(f"    Episode {episode_num} - AGENT GUESSING PROCESS:")
    print("   " + "="*50)

    #demo games
    for game_num in range(num_display_games):
        target = random.choice(solutions)
        obs, mask = eval_env.reset(target=target)
        done, guesses = False, 0

        print(f"\n    Game {game_num+1}: Target = {target.upper()}")
        print("   " + "-"*40)

        while not done and guesses < 6:
            obs_t = obs.unsqueeze(0).to(device)
            mask_t = mask.unsqueeze(0).to(device)

            with torch.no_grad():
                logits, _ = agent(obs_t)
                probs, current_temp = masked_softmax(logits, mask_t, episode_num, NUM_EPISODES)  # ← FIXED: catch both returns
                action = torch.argmax(probs).item()

            guess = vocab[action]
            obs, reward, done, mask = eval_env.step(action)
            guesses += 1

            # guess are shown 
            print(f"   Turn {guesses}: {guess.upper()}")

        if eval_env.history and eval_env.history[-1][0] == target:
            wins += 1
            print(f"   SOLVED in {guesses} turns!")
        else:
            print(f"    FAILED")

        total_guesses += min(guesses, 6)

    # Run remaining evaluation silently for statistics
    silent_wins = 0
    first_guesses = Counter()

    for i in range(EVAL_EPISODES - num_display_games):
        target = random.choice(solutions)
        obs, mask = eval_env.reset(target=target)
        done = False

        # Track first guess
        obs_t = obs.unsqueeze(0).to(device)
        mask_t = mask.unsqueeze(0).to(device)
        with torch.no_grad():
            logits, _ = agent(obs_t)
            probs, current_temp = masked_softmax(logits, mask_t, episode_num, NUM_EPISODES)  # ← FIXED
            first_action = torch.argmax(probs).item()
            first_guess = vocab[first_action]
            first_guesses[first_guess] += 1

        # Play silently
        while not done:
            obs_t = obs.unsqueeze(0).to(device)
            mask_t = mask.unsqueeze(0).to(device)
            with torch.no_grad():
                logits, _ = agent(obs_t)
                probs, current_temp = masked_softmax(logits, mask_t, episode_num, NUM_EPISODES)  # ← FIXED
                action = torch.argmax(probs).item()
            obs, _, done, mask = eval_env.step(action)

        if eval_env.history and eval_env.history[-1][0] == target:
            silent_wins += 1

    total_wins = wins + silent_wins
    win_rate = total_wins / EVAL_EPISODES
    avg_guesses = total_guesses / EVAL_EPISODES

    print(f"\n   Summary of {EVAL_EPISODES} games:")
    print(f"     Win Rate: {win_rate:.1%} | Avg Guesses: {avg_guesses:.2f}")
    print(f"     Top First Guesses: {first_guesses.most_common(5)}")
    print(f"     Current Temperature: {current_temp:.2f}")  

    return win_rate, avg_guesses